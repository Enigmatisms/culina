# 有关操作系统与访存优化
## LRU (最近最少使用缓存更新技术)
cache 空间并不大，当内存读取的位置发生较大改变时（移动到当前 cache line 外），操作系统自动将内存中的连续 64 字节读取到 cache 中，并覆盖原先的 cache 数据。其中一种覆盖策略就是 LRU: 将最近最少使用的 cache line 覆盖为新的值。我们在 `lru.cc` 中通过双向链表与哈希表实现了一个简单的 LRU 缓存（见 Leetcode 146 题）。其主要思想如下：
- 读取（get）以及写入（put）操作都需是 O(1) 时间复杂度。这要求：我们查找某一个 key 是否存在于缓存中时，需要通过 O(1) 的时间查找。并且，查找操作本身也算对缓存项的使用，不管是记录访问时间也好，还是别的操作（比如队列移动位置操作），都需要更新此访问的缓存项的访问时间（这是最近访问过的）。
- 写入操作 O(1) 一方面自然包括了查找对应项是否存在这一 O(1) 操作，如果不存在则直接写入，存在就同时需要更新时间，并且假设当前写入的项不存在且达到了缓存大小上限，我们需要pop最近最少使用的项。如何查找最近最少使用的项？如果只是记录访问时间，之后根据访问时间查找，则至少需要 O(logn) 的时间。故我们可能会使用队列进行维护。
- 但线性队列本身的移动开销是 O(n) 的，比如我们修改了当前队列中最后一项（在 pop 之前突然访问或者修改了这一最近最少使用的项），此时我们需要将此元素从队尾移动到队首。对于 deque 实现而言，这还是 O(1) 的，怕就怕我们需要先查找队列中某一个元素，将其移动到队首。此时的开销最坏情况是 O(n/2)。并且，如果使用的是线性表，我们如何用哈希去映射 key 与 对应队列单元？假设 HashMap 保存了 index, 那么每次发生了元素的移动，hashmap 很多地方都需要修改，显然不好。
- 所以：我们要找到 **移动开销O(1)** 的数据结构，并且方便同时操作首尾，并且利于key -> 队列元素的随机访问。则选择是：
    - 双向链表设计队列（注意 head, tail 虚拟节点可以简化实现）
    - HashMap 中存储每个 key 到 队列中存储单元的映射（value 就是指针）

## LFU (最近最不常使用)
此外，还有其他的缓存更新方法，比如 FIFO (简单队列形式，不考虑时间上的复用效率)，以及 LFU (使用次数最少)。接下来，我们思考 LFU 的实现。LFU 实现比 LRU 困难一些：LRU 的时序关系可以很好地被 encode 在队列中，但 LFU 相当于需要维护一个最小堆。且 LFU 同时也存在时间元素: 如果两个 items 被访问次数都是一致的，此时又按照 LRU 去实现了。解决方法：
- 用一个 LRU 表，每一个不同的访问次数都存在一个 LRU。当一个元素被访问之后，它将被移动到 LRU[访问次数 + 1] 表中，并插入到双向队列的队首。每次删除时，是在使用次数最少的 (也即下标最小的 LFU 中) LRU 队列中 pop 队尾。全局 Hash 与 LRU 一致，不过需要注意的是，可能需要存储对应的访问次数。